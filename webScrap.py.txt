from time import sleep
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import pandas as pd

busca = input("O que procura: ")

driver = webdriver.Chrome()
driver.get(f'https://www.zoom.com.br/search?q={busca}')

lista_relevantes = []
lista_menor_preco = []
lista_melhor_avaliado = []

def coletar_produtos():
    elementos = driver.find_element(By.CLASS_NAME, "Hits_Wrapper__iA3rM")
    produtos = elementos.find_elements(By.XPATH, ".//a[@class='ProductCard_ProductCard_Inner__gapsh']")
    return produtos

def extrair_info(produtos):
    lista = []
    for produto in produtos:
        produto_h2 = produto.find_element(By.XPATH, ".//h2[contains(@class,'ProductCard_ProductCard_Name')]")
        produto_nome = produto_h2.text
        produto_link = produto.get_attribute("href")
        lista.append([produto_nome, produto_link])
    return lista

# Coletar dados da primeira página
produtosPag1 = coletar_produtos()
lista_relevantes.extend(extrair_info(produtosPag1))

# Navegar pelas páginas e coletar dados
for pagina in range(2, 4):  # Páginas 2 e 3
    try:
        clickPag = WebDriverWait(driver, 10).until(
            EC.element_to_be_clickable((By.XPATH, f"//a[@aria-label='Página {pagina}']"))
        )
        driver.execute_script("arguments[0].click();", clickPag)
        sleep(3)

        produtos = coletar_produtos()
        lista_relevantes.extend(extrair_info(produtos))

    except Exception as e:
        print(f"Erro ao coletar produtos na página {pagina}: {str(e)}")

# Coletar produtos com menor preço
select = WebDriverWait(driver, 10).until(
    EC.element_to_be_clickable((By.CLASS_NAME, "Select_Select__1HNob"))
)
# Re-fetch the select element after any potential DOM changes
select = driver.find_element(By.CLASS_NAME, "Select_Select__1HNob")
select.find_element(By.XPATH, ".//option[@value='price_asc']").click()
sleep(3)

produtosPag1_MP = coletar_produtos()
lista_menor_preco.extend(extrair_info(produtosPag1_MP))

# Repetir para as páginas de menor preço
for pagina in range(2, 4):
    try:
        clickPag = WebDriverWait(driver, 10).until(
            EC.element_to_be_clickable((By.XPATH, f"//a[@aria-label='Página {pagina}']"))
        )
        driver.execute_script("arguments[0].click();", clickPag)
        sleep(3)

        produtos = coletar_produtos()
        lista_menor_preco.extend(extrair_info(produtos))

    except Exception as e:
        print(f"Erro ao coletar produtos na página {pagina} de menor preço: {str(e)}")

# Coletar produtos melhor avaliados
select = driver.find_element(By.CLASS_NAME, "Select_Select__1HNob")  # Re-fetch the select element
select.find_element(By.XPATH, ".//option[@value='rating_desc']").click()
sleep(3)

produtosPag1_MA = coletar_produtos()
lista_melhor_avaliado.extend(extrair_info(produtosPag1_MA))

# Repetir para as páginas de melhor avaliados
for pagina in range(2, 4):
    try:
        clickPag = WebDriverWait(driver, 10).until(
            EC.element_to_be_clickable((By.XPATH, f"//a[@aria-label='Página {pagina}']"))
        )
        driver.execute_script("arguments[0].click();", clickPag)
        sleep(3)

        produtos = coletar_produtos()
        lista_melhor_avaliado.extend(extrair_info(produtos))

    except Exception as e:
        print(f"Erro ao coletar produtos na página {pagina} de melhor avaliados: {str(e)}")

# Salvar os dados em CSV
df1 = pd.DataFrame(lista_relevantes, columns=['Produto', 'Link'])
df1.to_csv("produtos_relevantes.csv", index=False)

df2 = pd.DataFrame(lista_menor_preco, columns=['Produto', 'Link'])
df2.to_csv("lista_menor_preco.csv", index=False)

df3 = pd.DataFrame(lista_melhor_avaliado, columns=['Produto', 'Link'])
df3.to_csv("lista_melhor_avaliado.csv", index=False)

# Merge e salvar o custo-benefício
df_merged = df1.merge(df2, on='Link', how='outer').merge(df3, on='Link', how='outer')
df_merged.to_csv("CustoBeneficio.csv", index=False)

print("Scraping finalizado e dados salvos.")
sleep(3)
driver.quit()
